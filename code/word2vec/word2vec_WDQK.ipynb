{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-d062da05d3a5>:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  data = pd.read_csv('/Users/liuhy/Desktop/武Dong乾坤.txt', sep='/n', names=['sentence'], encoding='UTF-8')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./武Dong乾坤.txt', sep='/n', names=['sentence'], encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>------------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>第一卷</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>------------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>第一章 林动</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>第一章林动(本章免费)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence\n",
       "0  ------------\n",
       "1           第一卷\n",
       "2  ------------\n",
       "3        第一章 林动\n",
       "4   第一章林动(本章免费)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82762 entries, 0 to 82761\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  82762 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 646.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(82762, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'当林动费尽所有的力气睁开那有些沉重的眼皮时，简陋而整洁的房间顿时出现在眼中，熟悉的一幕让得他愣了愣，旋即连忙转头，果然是见到，在那房中，一男一女两道身影正坐在桌旁。'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[6, 'sentence']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理--将文本分词，封为一个list供训练使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/6m/0qpv989x76191k9prmny3p3w0000gn/T/jieba.cache\n",
      "Loading model cost 0.653 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "jieba.load_userdict('./my_dict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [' ', '(', ')', '（', '）', ',', '.', '!', '?', '|', '，', '。', '！', '？', '|', '｜', '……', '\"', '\"', '“', '”', \"'\", '‘', '’', '…', '------------']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentence'] = data['sentence'].apply(lambda sent: [word for word in jieba.lcut(sentence=sent, cut_all=False, HMM=True) if word not in stop_words])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[第一卷]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[第一章, 林动]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[第一章, 林动, 本章, 免费]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[唔]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[当, 林动, 费尽, 所有, 的, 力气, 睁开, 那, 有些, 沉重, 的, 眼皮, 时...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[爹, 娘]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[望, 着, 那, 两道, 身影, 林动, 赶忙, 提起, 精神, 小声, 的, 道]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[动儿, 你, 醒, 了]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence\n",
       "0                                                 []\n",
       "1                                              [第一卷]\n",
       "2                                                 []\n",
       "3                                          [第一章, 林动]\n",
       "4                                  [第一章, 林动, 本章, 免费]\n",
       "5                                                [唔]\n",
       "6  [当, 林动, 费尽, 所有, 的, 力气, 睁开, 那, 有些, 沉重, 的, 眼皮, 时...\n",
       "7                                             [爹, 娘]\n",
       "8        [望, 着, 那, 两道, 身影, 林动, 赶忙, 提起, 精神, 小声, 的, 道]\n",
       "9                                      [动儿, 你, 醒, 了]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_list = [sent for sent in list(data['sentence']) if len(sent) > 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用gensim完成word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import fasttext\n",
    "from gensim.models import word2vec\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 23:30:07,793 : INFO : collecting all words and their counts\n",
      "2022-03-28 23:30:07,794 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-03-28 23:30:07,846 : INFO : PROGRESS: at sentence #10000, processed 317114 words, keeping 17544 word types\n",
      "2022-03-28 23:30:07,903 : INFO : PROGRESS: at sentence #20000, processed 661903 words, keeping 24491 word types\n",
      "2022-03-28 23:30:07,959 : INFO : PROGRESS: at sentence #30000, processed 991328 words, keeping 30783 word types\n",
      "2022-03-28 23:30:08,015 : INFO : PROGRESS: at sentence #40000, processed 1296874 words, keeping 35557 word types\n",
      "2022-03-28 23:30:08,065 : INFO : PROGRESS: at sentence #50000, processed 1585353 words, keeping 38994 word types\n",
      "2022-03-28 23:30:08,118 : INFO : PROGRESS: at sentence #60000, processed 1883132 words, keeping 42564 word types\n",
      "2022-03-28 23:30:08,158 : INFO : collected 45067 word types from a corpus of 2082846 raw words and 66905 sentences\n",
      "2022-03-28 23:30:08,159 : INFO : Creating a fresh vocabulary\n",
      "2022-03-28 23:30:08,334 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 45067 unique words (100.0%% of original 45067, drops 0)', 'datetime': '2022-03-28T23:30:08.322539', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  4 2020, 02:22:02) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 23:30:08,337 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 2082846 word corpus (100.0%% of original 2082846, drops 0)', 'datetime': '2022-03-28T23:30:08.337407', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  4 2020, 02:22:02) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 23:30:08,624 : INFO : deleting the raw counts dictionary of 45067 items\n",
      "2022-03-28 23:30:08,626 : INFO : sample=0.001 downsamples 33 most-common words\n",
      "2022-03-28 23:30:08,626 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1726840.2668947687 word corpus (82.9%% of prior 2082846)', 'datetime': '2022-03-28T23:30:08.626879', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  4 2020, 02:22:02) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2022-03-28 23:30:09,074 : INFO : estimated required memory for 45067 words and 100 dimensions: 58587100 bytes\n",
      "2022-03-28 23:30:09,075 : INFO : resetting layer weights\n",
      "2022-03-28 23:30:09,100 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-03-28T23:30:09.100007', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  4 2020, 02:22:02) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2022-03-28 23:30:09,100 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 45067 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-03-28T23:30:09.100771', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  4 2020, 02:22:02) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 23:30:10,109 : INFO : EPOCH 1 - PROGRESS: at 80.35% examples, 1403005 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 23:30:10,325 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 23:30:10,330 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 23:30:10,333 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 23:30:10,333 : INFO : EPOCH - 1 : training on 2082846 raw words (1726648 effective words) took 1.2s, 1408580 effective words/s\n",
      "2022-03-28 23:30:11,345 : INFO : EPOCH 2 - PROGRESS: at 83.26% examples, 1447414 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 23:30:11,520 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 23:30:11,524 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 23:30:11,530 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 23:30:11,530 : INFO : EPOCH - 2 : training on 2082846 raw words (1726768 effective words) took 1.2s, 1450639 effective words/s\n",
      "2022-03-28 23:30:12,540 : INFO : EPOCH 3 - PROGRESS: at 84.23% examples, 1466860 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 23:30:12,705 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 23:30:12,709 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 23:30:12,711 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 23:30:12,711 : INFO : EPOCH - 3 : training on 2082846 raw words (1726667 effective words) took 1.2s, 1469183 effective words/s\n",
      "2022-03-28 23:30:13,721 : INFO : EPOCH 4 - PROGRESS: at 87.78% examples, 1524667 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 23:30:13,834 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 23:30:13,838 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 23:30:13,839 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 23:30:13,839 : INFO : EPOCH - 4 : training on 2082846 raw words (1726804 effective words) took 1.1s, 1539011 effective words/s\n",
      "2022-03-28 23:30:14,848 : INFO : EPOCH 5 - PROGRESS: at 89.81% examples, 1559061 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 23:30:14,943 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 23:30:14,950 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 23:30:14,951 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 23:30:14,952 : INFO : EPOCH - 5 : training on 2082846 raw words (1727048 effective words) took 1.1s, 1560761 effective words/s\n",
      "2022-03-28 23:30:15,969 : INFO : EPOCH 6 - PROGRESS: at 84.23% examples, 1460573 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 23:30:16,124 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 23:30:16,130 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 23:30:16,131 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 23:30:16,131 : INFO : EPOCH - 6 : training on 2082846 raw words (1727319 effective words) took 1.2s, 1475479 effective words/s\n",
      "2022-03-28 23:30:17,142 : INFO : EPOCH 7 - PROGRESS: at 83.26% examples, 1450246 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 23:30:17,321 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 23:30:17,329 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 23:30:17,330 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 23:30:17,331 : INFO : EPOCH - 7 : training on 2082846 raw words (1726285 effective words) took 1.2s, 1448371 effective words/s\n",
      "2022-03-28 23:30:18,338 : INFO : EPOCH 8 - PROGRESS: at 85.24% examples, 1483451 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 23:30:18,495 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 23:30:18,502 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 23:30:18,502 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 23:30:18,503 : INFO : EPOCH - 8 : training on 2082846 raw words (1726493 effective words) took 1.2s, 1477447 effective words/s\n",
      "2022-03-28 23:30:19,518 : INFO : EPOCH 9 - PROGRESS: at 86.17% examples, 1490947 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 23:30:19,669 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 23:30:19,674 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 23:30:19,680 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 23:30:19,681 : INFO : EPOCH - 9 : training on 2082846 raw words (1726416 effective words) took 1.2s, 1473818 effective words/s\n",
      "2022-03-28 23:30:20,689 : INFO : EPOCH 10 - PROGRESS: at 88.31% examples, 1536438 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 23:30:20,801 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 23:30:20,805 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 23:30:20,806 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 23:30:20,806 : INFO : EPOCH - 10 : training on 2082846 raw words (1726857 effective words) took 1.1s, 1543626 effective words/s\n",
      "2022-03-28 23:30:21,814 : INFO : EPOCH 11 - PROGRESS: at 84.23% examples, 1468988 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 23:30:21,982 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 23:30:21,986 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 23:30:21,988 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 23:30:21,988 : INFO : EPOCH - 11 : training on 2082846 raw words (1726759 effective words) took 1.2s, 1467943 effective words/s\n",
      "2022-03-28 23:30:23,002 : INFO : EPOCH 12 - PROGRESS: at 83.73% examples, 1452414 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 23:30:23,162 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 23:30:23,165 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 23:30:23,166 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 23:30:23,167 : INFO : EPOCH - 12 : training on 2082846 raw words (1727090 effective words) took 1.2s, 1472395 effective words/s\n",
      "2022-03-28 23:30:24,177 : INFO : EPOCH 13 - PROGRESS: at 90.75% examples, 1574166 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 23:30:24,262 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 23:30:24,265 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 23:30:24,270 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 23:30:24,271 : INFO : EPOCH - 13 : training on 2082846 raw words (1727543 effective words) took 1.1s, 1573454 effective words/s\n",
      "2022-03-28 23:30:25,276 : INFO : EPOCH 14 - PROGRESS: at 88.83% examples, 1543093 words/s, in_qsize 6, out_qsize 0\n",
      "2022-03-28 23:30:25,383 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 23:30:25,388 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 23:30:25,394 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 23:30:25,395 : INFO : EPOCH - 14 : training on 2082846 raw words (1726874 effective words) took 1.1s, 1540592 effective words/s\n",
      "2022-03-28 23:30:26,403 : INFO : EPOCH 15 - PROGRESS: at 90.28% examples, 1570174 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 23:30:26,492 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 23:30:26,497 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 23:30:26,501 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 23:30:26,502 : INFO : EPOCH - 15 : training on 2082846 raw words (1726679 effective words) took 1.1s, 1570082 effective words/s\n",
      "2022-03-28 23:30:27,508 : INFO : EPOCH 16 - PROGRESS: at 88.83% examples, 1543316 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 23:30:27,615 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 23:30:27,619 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 23:30:27,621 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 23:30:27,622 : INFO : EPOCH - 16 : training on 2082846 raw words (1726253 effective words) took 1.1s, 1547568 effective words/s\n",
      "2022-03-28 23:30:28,631 : INFO : EPOCH 17 - PROGRESS: at 90.28% examples, 1566577 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 23:30:28,725 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 23:30:28,728 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 23:30:28,734 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 23:30:28,735 : INFO : EPOCH - 17 : training on 2082846 raw words (1727205 effective words) took 1.1s, 1559822 effective words/s\n",
      "2022-03-28 23:30:29,748 : INFO : EPOCH 18 - PROGRESS: at 86.17% examples, 1495412 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 23:30:29,873 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 23:30:29,876 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 23:30:29,881 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 23:30:29,882 : INFO : EPOCH - 18 : training on 2082846 raw words (1727126 effective words) took 1.1s, 1514057 effective words/s\n",
      "2022-03-28 23:30:30,888 : INFO : EPOCH 19 - PROGRESS: at 89.81% examples, 1559865 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 23:30:30,981 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 23:30:30,990 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 23:30:30,990 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 23:30:30,991 : INFO : EPOCH - 19 : training on 2082846 raw words (1726431 effective words) took 1.1s, 1563114 effective words/s\n",
      "2022-03-28 23:30:31,999 : INFO : EPOCH 20 - PROGRESS: at 90.75% examples, 1578624 words/s, in_qsize 5, out_qsize 0\n",
      "2022-03-28 23:30:32,083 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-03-28 23:30:32,088 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-03-28 23:30:32,089 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-03-28 23:30:32,090 : INFO : EPOCH - 20 : training on 2082846 raw words (1726610 effective words) took 1.1s, 1581511 effective words/s\n",
      "2022-03-28 23:30:32,090 : INFO : Word2Vec lifecycle event {'msg': 'training on 41656920 raw words (34535875 effective words) took 23.0s, 1502247 effective words/s', 'datetime': '2022-03-28T23:30:32.090761', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  4 2020, 02:22:02) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2022-03-28 23:30:32,091 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=45067, vector_size=100, alpha=0.025)', 'datetime': '2022-03-28T23:30:32.091856', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  4 2020, 02:22:02) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model = word2vec.Word2Vec(sentences=sents_list, window=5, sg=0, min_count=1, negative=5, epochs=20)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 23:35:34,607 : INFO : Word2Vec lifecycle event {'fname_or_handle': './word2vec.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-03-28T23:35:34.607005', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  4 2020, 02:22:02) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}\n",
      "2022-03-28 23:35:34,608 : INFO : not storing attribute cum_table\n",
      "2022-03-28 23:35:34,675 : INFO : saved ./word2vec.model\n"
     ]
    }
   ],
   "source": [
    "model.save('./word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 23:54:57,213 : INFO : KeyedVectors lifecycle event {'fname_or_handle': './word2vec_WDQK.wordvectors', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-03-28T23:54:57.213911', 'gensim': '4.1.2', 'python': '3.8.5 (default, Sep  4 2020, 02:22:02) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'saving'}\n",
      "2022-03-28 23:54:57,251 : INFO : saved ./word2vec_WDQK.wordvectors\n"
     ]
    }
   ],
   "source": [
    "word_vectors.save('./word2vec_WDQK.wordvectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import keyedvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors_kv = keyedvectors.KeyedVectors.load('./word2vec_WDQK.wordvectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_vectors_kv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(word_vectors_kv.key_to_index.keys())\n",
    "vectors = list(word_vectors_kv.vectors)\n",
    "vectors = list(map(list, (vec for vec in vectors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45067, 45067)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words), len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_vectors = list(map(lambda x: ' '.join(x), [[str(vec_value) for vec_value in vec] for vec in vectors]))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45067"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(str_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors_dict = list(zip(words, str_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = pd.DataFrame(word_vectors_dict, columns=['word', 'vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>的</td>\n",
       "      <td>-0.5071854 0.43013474 0.9458973 -0.46390238 -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>是</td>\n",
       "      <td>-1.8130685 -0.5626644 -0.14609273 2.3658862 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>了</td>\n",
       "      <td>0.5621393 1.2186996 0.55153453 -1.5065137 -1.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>林动</td>\n",
       "      <td>-1.7170911 0.071835935 0.3490898 -1.7563043 -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>在</td>\n",
       "      <td>0.6984693 1.3269782 -0.75043553 0.75340396 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word                                             vector\n",
       "0    的  -0.5071854 0.43013474 0.9458973 -0.46390238 -1...\n",
       "1    是  -1.8130685 -0.5626644 -0.14609273 2.3658862 1....\n",
       "2    了  0.5621393 1.2186996 0.55153453 -1.5065137 -1.6...\n",
       "3   林动  -1.7170911 0.071835935 0.3490898 -1.7563043 -0...\n",
       "4    在  0.6984693 1.3269782 -0.75043553 0.75340396 0.0..."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.to_csv('./embedding.txt',index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}